{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PageRank algorithm using MapReduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully parsed './data/padgett.xml' and created './data/padgett_input.txt'.\n",
      "Found 16 nodes and 40 marriage links.\n",
      "file saved: ./data/padgett_input.txt\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "\n",
    "def parse_padgett_data(xml_file_path: str, output_txt_path: str):\n",
    "    \"\"\"\n",
    "    Parses the Padgett Florentine families XML file to extract nodes\n",
    "    and marriage links (PADGM network with value=1.0), writing them\n",
    "    to a text file suitable for MRJob input.\n",
    "\n",
    "    Format:\n",
    "        NODE_ID\\t!NODE  (for declaring all nodes)\n",
    "        SOURCE_ID\\tTARGET_ID (for representing marriage links)\n",
    "\n",
    "    Args:\n",
    "        xml_file_path (str): Path to the input padgett.xml file.\n",
    "        output_txt_path (str): Path where the output .txt file will be saved.\n",
    "    \"\"\"\n",
    "    nodes = set()\n",
    "    edges = []\n",
    "\n",
    "    try:\n",
    "        if not os.path.exists(xml_file_path):\n",
    "             print(f\"Error: Input file not found at {xml_file_path}\")\n",
    "             return False\n",
    "\n",
    "        # Parse the XML tree\n",
    "        tree = ET.parse(xml_file_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        # --- Extract all node IDs ---\n",
    "        # Find the 'agent' nodeclass and extract all node IDs within it\n",
    "        agent_nodes = root.findall(\"./MetaNetwork/nodes/nodeclass[@type='agent']/node\")\n",
    "        for node in agent_nodes:\n",
    "            node_id = node.get('id')\n",
    "            if node_id:\n",
    "                nodes.add(node_id)\n",
    "\n",
    "        # --- Extract relevant links (marriage network PADGM, value=1.0000) ---\n",
    "        marriage_links = root.findall(\"./MetaNetwork/networks/network[@id='PADGM']/link\")\n",
    "        for link in marriage_links:\n",
    "            source = link.get('source')\n",
    "            target = link.get('target')\n",
    "            value = link.get('value')\n",
    "\n",
    "            if value == \"1.0000\" and source and target:\n",
    "                if source in nodes and target in nodes:\n",
    "                    edges.append((source, target))\n",
    "\n",
    "        with open(output_txt_path, 'w') as f_out:\n",
    "            for node_id in sorted(list(nodes)):\n",
    "                f_out.write(f\"{node_id}\\t!NODE\\n\")\n",
    "\n",
    "            for source, target in edges:\n",
    "                f_out.write(f\"{source}\\t{target}\\n\")\n",
    "\n",
    "        print(f\"Successfully parsed '{xml_file_path}' and created '{output_txt_path}'.\")\n",
    "        print(f\"Found {len(nodes)} nodes and {len(edges)} marriage links.\")\n",
    "        return True\n",
    "\n",
    "    except ET.ParseError as e:\n",
    "        print(f\"Error parsing XML file '{xml_file_path}': {e}\")\n",
    "        return False\n",
    "    except IOError as e:\n",
    "        print(f\"Error writing to output file '{output_txt_path}': {e}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return False\n",
    "\n",
    "input_xml = './data/padgett.xml'\n",
    "output_txt = './data/padgett_input.txt' # Name for the generated file\n",
    "\n",
    "if parse_padgett_data(input_xml, output_txt):\n",
    "    print(f\"file saved: {output_txt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting page_rank.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile page_rank.py\n",
    "# Save this cell's content to page_rank.py\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import json\n",
    "\n",
    "class MRPageRank(MRJob):\n",
    "    \"\"\"\n",
    "    MRJob Step 1: Initialize Graph and Assign Initial Ranks.\n",
    "    Reads the parsed data (nodes and edges).\n",
    "    Outputs each node with its initial PageRank and adjacency list.\n",
    "    \"\"\"\n",
    "    N_NODES = 16\n",
    "    DAMPING_FACTOR = 0.85\n",
    "\n",
    "    # INITIALIZATION STEPS \n",
    "    def mapper_init_graph(self, _, line):\n",
    "        \"\"\"\n",
    "        Mapper for initialization step.\n",
    "        Input: One line from parsed_padgett_data.txt\n",
    "               (e.g., \"MEDICI\\t!NODE\" or \"ALBIZZI\\tGINORI\")\n",
    "        Output: Yields (node, neighbor_or_marker) pairs.\n",
    "                Key: The source node (family name).\n",
    "                Value: Either the target node (neighbor family name)\n",
    "                       or the '!NODE' marker.\n",
    "        \"\"\"\n",
    "        line = line.strip()\n",
    "\n",
    "        # Split the line into parts based on the tab character\n",
    "        parts = line.split('\\t', 1) # Split only on the first tab\n",
    "\n",
    "        if len(parts) == 2:\n",
    "            node_key = parts[0]\n",
    "            value_part = parts[1]\n",
    "\n",
    "            # Yield the node as the key and the second part as the value\n",
    "            # The reducer will group these values by node_key\n",
    "            yield node_key, value_part\n",
    "\n",
    "\n",
    "    def reducer_init_graph(self, node, values):\n",
    "        \"\"\"\n",
    "        Reducer for initialization step.\n",
    "        Input: node (family name), iterator of values ('!NODE' or neighbor names)\n",
    "        Output: Yields (node, json_string_of_tuple) where tuple is (initial_rank, [neighbor_list])\n",
    "                Using JSON string for output value ensures correct handling by subsequent mrjob steps.\n",
    "        \"\"\"\n",
    "        neighbors = []\n",
    "        node_declared = False # Flag to confirm '!NODE' was seen or links exist\n",
    "\n",
    "        # Iterate through all values received for this node\n",
    "        for value in values:\n",
    "            node_declared = True\n",
    "            if value != '!NODE':\n",
    "                neighbors.append(value)\n",
    "\n",
    "        # Only output if the node was actually declared in the input\n",
    "        if node_declared:\n",
    "            # Initialize PageRank\n",
    "            initial_rank = 1.0 / self.N_NODES\n",
    "\n",
    "            # Sort neighbors for easier debugging\n",
    "            neighbors.sort()\n",
    "\n",
    "            output_value = (initial_rank, neighbors)\n",
    "\n",
    "            # Yield the node and the JSON encoded tuple (rank, neighbors)\n",
    "            yield node, json.dumps(output_value)\n",
    "\n",
    "    # RANK CALCULATION STEPS\n",
    "    def mapper_pagerank_iter(self, node, value_str):\n",
    "        \"\"\"\n",
    "        Mapper for a single PageRank iteration.\n",
    "        Input: key=node (family name), value=JSON string \"(current_rank, [neighbors])\"\n",
    "            (e.g., node=\"MEDICI\", value_str=\"[0.0625, [\\\"ACCIAIUOL\\\", ...]]\")\n",
    "        Output:\n",
    "            1. Yields (node, ('NODE', [neighbors])) to pass graph structure along.\n",
    "            2. Yields (neighbor, ('RANK', contribution)) for each neighbor.\n",
    "        \"\"\"\n",
    "        # Load the tuple (current_rank, neighbors) from the JSON string\n",
    "        try:\n",
    "            current_rank, neighbors = json.loads(value_str)\n",
    "        except (json.JSONDecodeError, ValueError) as e:\n",
    "            # Handle potential errors if the input isn't valid JSON or doesn't unpack correctly\n",
    "            self.increment_counter('Error', 'JSONDecodeError', 1)\n",
    "            return\n",
    "\n",
    "        # 1. Emit the graph structure information for this node.\n",
    "        #    The value is a tuple starting with 'NODE' marker.\n",
    "        yield node, ('NODE', neighbors)\n",
    "\n",
    "        # 2. Distribute rank contribution to neighbors.\n",
    "        if neighbors: # Only distribute rank if there are outgoing links\n",
    "            num_neighbors = len(neighbors)\n",
    "            contribution = current_rank / num_neighbors\n",
    "\n",
    "            # For each neighbor, emit the rank contribution.\n",
    "            # The value is a tuple starting with 'RANK' marker.\n",
    "            for neighbor in neighbors:\n",
    "                yield neighbor, ('RANK', contribution)\n",
    "        # else:\n",
    "            # This is a dangling node (no outgoing links).\n",
    "            # In basic PageRank, its rank \"disappears\" in this step,\n",
    "            # but the damping factor in the reducer compensates for this lost rank globally.\n",
    "            # More advanced implementations might distribute this rank differently.\n",
    "            pass\n",
    "\n",
    "    def reducer_pagerank_iter(self, node, values):\n",
    "        \"\"\"\n",
    "        Reducer for a single PageRank iteration.\n",
    "        Input: key=node (family name),\n",
    "            value=iterator of tuples like ('NODE', [neighbors]) or ('RANK', contribution)\n",
    "        Output: Yields (node, json_string_of_tuple) where tuple is (new_rank, [neighbor_list])\n",
    "                (same format as the input to the iteration mapper)\n",
    "        \"\"\"\n",
    "        total_received_rank = 0.0\n",
    "        neighbors = []\n",
    "        node_info_found = False # Flag to ensure we found the ('NODE', neighbors) tuple\n",
    "\n",
    "        # Constants for the PageRank calculation\n",
    "        N = self.N_NODES     # Get N from class variable\n",
    "        damping_factor = self.DAMPING_FACTOR\n",
    "\n",
    "        # Iterate through all values received for this node\n",
    "        for value_type, data in values:\n",
    "            if value_type == 'NODE':\n",
    "                neighbors = data # Get the list of neighbors\n",
    "                node_info_found = True\n",
    "            elif value_type == 'RANK':\n",
    "                total_received_rank += data # Add the received rank contribution\n",
    "            # else:\n",
    "                # Optional: handle unexpected value types\n",
    "                # self.increment_counter('Error', 'UnknownValueTypeInReducer', 1)\n",
    "\n",
    "        # We must have the node structure info to proceed\n",
    "        if node_info_found:\n",
    "            # Calculate new PageRank\n",
    "            new_rank = (1 - damping_factor) / N + (damping_factor * total_received_rank)\n",
    "\n",
    "            output_value = (new_rank, neighbors) # Keep the neighbors list\n",
    "\n",
    "            yield node, json.dumps(output_value)\n",
    "        # else:\n",
    "            # This case shouldn't happen if the mapper always sends ('NODE', ...)\n",
    "            # but adding a counter helps debug if it does.\n",
    "            # self.increment_counter('Error', 'NodeInfoMissingInReducer', 1)\n",
    "\n",
    "    def steps(self):\n",
    "            \"\"\"Define the sequence of MapReduce steps.\"\"\"\n",
    "            # Create a list of MRStep objects for the iterations\n",
    "            iteration_steps = [\n",
    "                MRStep(mapper=self.mapper_pagerank_iter,\n",
    "                    reducer=self.reducer_pagerank_iter)\n",
    "                for _ in range(50) # Create 10 identical iteration steps\n",
    "            ]\n",
    "\n",
    "            # Return the list starting with the initialization step,\n",
    "            # followed by all the iteration steps.\n",
    "            return [\n",
    "                MRStep(mapper=self.mapper_init_graph,\n",
    "                    reducer=self.reducer_init_graph)\n",
    "            ] + iteration_steps # Concatenate the lists\n",
    "\n",
    "# This makes the script runnable from the command line\n",
    "if __name__ == '__main__':\n",
    "    MRPageRank.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Creating temp directory /var/folders/49/4w4d2pt94bjc7rwd_ckjbhzh0000gn/T/page_rank.tilen.20250504.000550.350583\n",
      "Running step 1 of 51...\n",
      "Running step 2 of 51...\n",
      "Running step 3 of 51...\n",
      "Running step 4 of 51...\n",
      "Running step 5 of 51...\n",
      "Running step 6 of 51...\n",
      "Running step 7 of 51...\n",
      "Running step 8 of 51...\n",
      "Running step 9 of 51...\n",
      "Running step 10 of 51...\n",
      "Running step 11 of 51...\n",
      "Running step 12 of 51...\n",
      "Running step 13 of 51...\n",
      "Running step 14 of 51...\n",
      "Running step 15 of 51...\n",
      "Running step 16 of 51...\n",
      "Running step 17 of 51...\n",
      "Running step 18 of 51...\n",
      "Running step 19 of 51...\n",
      "Running step 20 of 51...\n",
      "Running step 21 of 51...\n",
      "Running step 22 of 51...\n",
      "Running step 23 of 51...\n",
      "Running step 24 of 51...\n",
      "Running step 25 of 51...\n",
      "Running step 26 of 51...\n",
      "Running step 27 of 51...\n",
      "Running step 28 of 51...\n",
      "Running step 29 of 51...\n",
      "Running step 30 of 51...\n",
      "Running step 31 of 51...\n",
      "Running step 32 of 51...\n",
      "Running step 33 of 51...\n",
      "Running step 34 of 51...\n",
      "Running step 35 of 51...\n",
      "Running step 36 of 51...\n",
      "Running step 37 of 51...\n",
      "Running step 38 of 51...\n",
      "Running step 39 of 51...\n",
      "Running step 40 of 51...\n",
      "Running step 41 of 51...\n",
      "Running step 42 of 51...\n",
      "Running step 43 of 51...\n",
      "Running step 44 of 51...\n",
      "Running step 45 of 51...\n",
      "Running step 46 of 51...\n",
      "Running step 47 of 51...\n",
      "Running step 48 of 51...\n",
      "Running step 49 of 51...\n",
      "Running step 50 of 51...\n",
      "Running step 51 of 51...\n",
      "job output is in /var/folders/49/4w4d2pt94bjc7rwd_ckjbhzh0000gn/T/page_rank.tilen.20250504.000550.350583/output\n",
      "Streaming final output from /var/folders/49/4w4d2pt94bjc7rwd_ckjbhzh0000gn/T/page_rank.tilen.20250504.000550.350583/output...\n",
      "Removing temp directory /var/folders/49/4w4d2pt94bjc7rwd_ckjbhzh0000gn/T/page_rank.tilen.20250504.000550.350583...\n"
     ]
    }
   ],
   "source": [
    "!python page_rank.py ./data/padgett_input.txt > ./output/step1_output_50.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "page_rank",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
